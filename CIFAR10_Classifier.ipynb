{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR10 Classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMxF0gmJwRdpbLL7/ZtAOX3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uGRN9pIPMWO3"},"source":["# 1. Load and normalize CIFAR10"]},{"cell_type":"code","metadata":{"id":"VCRzWkBH3X5s","executionInfo":{"status":"ok","timestamp":1635004865205,"user_tz":-120,"elapsed":26558,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtAHXySI3yS7","executionInfo":{"status":"ok","timestamp":1635004963884,"user_tz":-120,"elapsed":2205,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}},"outputId":"e0293cea-7d9a-4538-f5cf-3dbdc959a91a"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","batch_size = 4\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","print(len(trainset))\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","50000\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"id":"BoWX6oa4KnRI","executionInfo":{"status":"aborted","timestamp":1635004873029,"user_tz":-120,"elapsed":13,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# func to plot image\n","def imgshow(img):\n","  img = img / 2 + 0.5 # unnormalize\n","  npimg = img.numpy()\n","  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","  plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)  \n","images, labels = dataiter.next()  # This will give a batch_size of images\n","\n","imgshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' \\t\\t'.join('%5s' % classes[labels[j]] for j in range(batch_size)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BvPbU16VNHrp"},"source":["# 2. Define a Convolutional Neural Network"]},{"cell_type":"code","metadata":{"id":"0XkM__VPNMax","executionInfo":{"status":"aborted","timestamp":1635004873030,"user_tz":-120,"elapsed":13,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","print(net)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mdox3rSCPmu0"},"source":["# 3. Define a Loss function and optimizer"]},{"cell_type":"code","metadata":{"id":"XnZKe-CXPqXR","executionInfo":{"status":"aborted","timestamp":1635004873032,"user_tz":-120,"elapsed":15,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GKUt98P5RI_8"},"source":["# 4. Train the network"]},{"cell_type":"code","metadata":{"id":"e-adT1T7RNGD","executionInfo":{"status":"aborted","timestamp":1635004873034,"user_tz":-120,"elapsed":17,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkPHAlw8YvI6","executionInfo":{"status":"aborted","timestamp":1635004873035,"user_tz":-120,"elapsed":18,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["PATH = './cifar_net.pth'\n","torch.save(net.state_dict(), PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcXV5RlIY4U-"},"source":["# 5. Test the network on the test data"]},{"cell_type":"code","metadata":{"id":"_TZR1X9tY8JQ","executionInfo":{"status":"aborted","timestamp":1635004873036,"user_tz":-120,"elapsed":18,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["dataiter = iter(testloader)\n","images, labels = dataiter.next()\n","\n","# print images\n","imgshow(torchvision.utils.make_grid(images))\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ei6AR_IKZcWs","executionInfo":{"status":"aborted","timestamp":1635004873037,"user_tz":-120,"elapsed":19,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["net = Net()\n","net.load_state_dict(torch.load(PATH))\n","\n","outputs = net(images)\n","_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n","                              for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKR0XqM0aeV7","executionInfo":{"status":"aborted","timestamp":1635004873039,"user_tz":-120,"elapsed":21,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["# Let's look at the performances on the whole dataset\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        # calculate outputs by running images through the network\n","        outputs = net(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0cQ5cuabSxQ","executionInfo":{"status":"aborted","timestamp":1635004873040,"user_tz":-120,"elapsed":22,"user":{"displayName":"Alessandro Versace","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0YtheXUuos8zo8MyzO0zL5RoorpurKd9_2bltSQ=s64","userId":"13329179161963555112"}}},"source":["# Let's see how the model performed on the single classes\n","\n","# prepare to count predictions for each class\n","correct_pred = {classname: 0 for classname in classes}\n","total_pred = {classname: 0 for classname in classes}\n","\n","# again no gradients needed\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predictions = torch.max(outputs, 1)\n","        # collect the correct predictions for each class\n","        for label, prediction in zip(labels, predictions):\n","            if label == prediction:\n","                correct_pred[classes[label]] += 1\n","            total_pred[classes[label]] += 1\n","\n","\n","# print accuracy for each class\n","for classname, correct_count in correct_pred.items():\n","    accuracy = 100 * float(correct_count) / total_pred[classname]\n","    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n","                                                   accuracy))"],"execution_count":null,"outputs":[]}]}