{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM",
      "provenance": [],
      "collapsed_sections": [
        "jiwWzjzSio-h",
        "g1GznJhObXPk",
        "UPwkOR8taVdN",
        "21wjiwvW-OPQ",
        "z0MWgLingzhw",
        "lrLs_T2Qd0kc",
        "Gr9BxL8zeBfv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# Torch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbtEmI1AiTkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3980722a-b4aa-4aa4-80a8-468a50eedd59"
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip3 install \"colorama\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.3.1\n",
            "  Using cached torch-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (734.6 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.3.1) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.5.0 requires torch==1.4.0, but you have torch 1.3.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.3.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.3.1\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Collecting torch==1.4.0\n",
            "  Using cached torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.7/dist-packages (7.0.0.post3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Dataset GTEA61"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOhXMNqjMed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab1fe64-f939-46f6-dc8f-f688c80008ce"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "import sys, os\n",
        "\n",
        "if not os.path.isfile('/content/GTEA61.zip'):\n",
        "  !gdown --id 1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk # 3-5 min\n",
        "  !jar xvf  \"/content/GTEA61.zip\"\n",
        "\n",
        "if not os.path.isdir('/content/GTEA61'):\n",
        "  print(\"Dataset doesn't exist\")\n",
        "\n",
        "#Weights\n",
        "if not os.path.isfile(\"/content/best_model_state_dict_rgb_split2.pth\"):\n",
        "  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5 # 3-5 min\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk0rtAlnSlDF"
      },
      "source": [
        "\n",
        "# Download Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8xcWfReaSd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314b345f-b77b-4e48-8c4e-f3f0eceeba06"
      },
      "source": [
        "!git clone \"https://github.com/plana93/Homework_AIML.git\" \n",
        "#!rm -r \"/content/Homework_AIML\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Homework_AIML' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl6fSd3MXofW"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from colorama import init\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "from torchvision.models import resnet34\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/Homework_AIML/\")\n",
        "import Homework_AIML\n",
        "from Homework_AIML import *\n",
        "\n",
        "from gtea_dataset import GTEA61, GTEA61_flow, GTEA61_2Stream\n",
        "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1GznJhObXPk"
      },
      "source": [
        "#**Learning without Temporal information** (avgpool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy4KrHClbAmC"
      },
      "source": [
        "#MAIN PARAMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tz9mHPbCYW"
      },
      "source": [
        "#homework_step = 0 #--> Learning without Temporal information (avgpool)\n",
        "#homework_step = 1 #--> Learning with Temporal information (LSTM)\n",
        "homework_step = 2 #--> Learning with Spatio-Temporal information (ConvLSTM)\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = '/content/GTEA61/' #path dataset\n",
        "model_folder = '/content/saved_models/' + \"/\" + \"homework_step\"+ str(homework_step) + \"/\" #path to save model \n",
        "if not os.path.isdir(model_folder):\n",
        "    os.makedirs(model_folder)\n",
        "\n",
        "\n",
        "# All this param can be change!\n",
        "\n",
        "NUM_CLASSES = 61     \n",
        "BATCH_SIZE = 64 \n",
        "LR = 0.001            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 200     # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = [25, 75, 150] # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "MEM_SIZE = 512       # Dim of internal state of LSTM or ConvLSTM\n",
        "SEQ_LEN = 3          # Num Frames\n",
        "\n",
        "# this dictionary is needed for the logger class\n",
        "parameters = {'DEVICE':DEVICE, 'NUM_CLASSES':NUM_CLASSES, 'BATCH_SIZE':BATCH_SIZE,\n",
        "             'LR':LR, 'MOMENTUM':MOMENTUM, 'WEIGHT_DECAY':WEIGHT_DECAY, 'NUM_EPOCHS':NUM_EPOCHS,\n",
        "             'STEP_SIZE':STEP_SIZE, 'GAMMA':GAMMA, 'MEM_SIZE':MEM_SIZE, 'SEQ_LEN':SEQ_LEN}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPwkOR8taVdN"
      },
      "source": [
        "#Dataloaders & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT_Gy79SgBLq"
      },
      "source": [
        "# Normalize\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), normalize])\n",
        "spatial_transform_val = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69vfGGhjKa_",
        "outputId": "799b64a2-2178-44ac-bb62-c16ec93e24d8"
      },
      "source": [
        "# Prepare Pytorch train/test Datasets\n",
        "train_dataset = GTEA61(DATA_DIR, split='train', transform=spatial_transform, seq_len=SEQ_LEN)\n",
        "test_dataset = GTEA61(DATA_DIR, split='test', transform=spatial_transform_val, seq_len=SEQ_LEN)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n",
        "\n",
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S2', 'S3', 'S1', 'S4']\n",
            "['S2', 'S3', 'S1', 'S4']\n",
            "Train Dataset: 341\n",
            "Test Dataset: 116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wjiwvW-OPQ"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMWuE-4SHxoY"
      },
      "source": [
        "import torch\n",
        "import resnetMod\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n",
        "# LSTM\n",
        "class MyLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weight_ih = Parameter(torch.randn(4 * hidden_size, input_size))\n",
        "        self.weight_hh = Parameter(torch.randn(4 * hidden_size, input_size))\n",
        "        self.bias_ih = Parameter(torch.randn(4 * hidden_size))\n",
        "        self.bias_hh = Parameter(torch.randn(4 * hidden_size))\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1)).cuda()))\n",
        "        hx, cx = state\n",
        "        gates = (torch.mm(x, self.weight_ih.t()) + self.bias_ih + torch.mm(hx, self.weight_hh.t()) + self.bias_hh)\n",
        "        inputgate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
        "\n",
        "        inputgate = torch.sigmoid(inputgate)\n",
        "        forgetgate = torch.sigmoid(forgetgate)\n",
        "        outgate = torch.sigmoid(outgate)\n",
        "        cellgate = torch.tanh(cellgate)\n",
        "\n",
        "        cy = forgetgate * cx + inputgate * cellgate\n",
        "        hy = outgate * torch.tanh(cy)\n",
        "\n",
        "        return  hy, cy\n",
        "\n",
        "\n",
        "#ConvLSTM\n",
        "class MyConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=3, stride=1, padding=1):\n",
        "        super(MyConvLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.conv_i_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_i_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_f_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_f_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_c_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_c_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_o_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_o_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_i_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_f_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_c_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_o_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_hh.weight)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()))\n",
        "            \n",
        "        hx, cx = state\n",
        "        \n",
        "        # Same approach of LSTM-only but processing input with convolution before passing through gates\n",
        "        inputgate = self.conv_i_xx(x) + self.conv_i_hh(hx)\n",
        "        forgetgate = self.conv_f_xx(x) + self.conv_f_hh(hx)\n",
        "        cellgate = self.conv_c_xx(x) + self.conv_c_hh(hx)\n",
        "        outgate = self.conv_o_xx(x) + self.conv_o_hh(hx)\n",
        "\n",
        "        inputgate = torch.sigmoid(inputgate)\n",
        "        forgetgate = torch.sigmoid(forgetgate)\n",
        "        outgate = torch.sigmoid(outgate)\n",
        "        cellgate = torch.tanh(cellgate)\n",
        "\n",
        "        cy = forgetgate * cx + inputgate * cellgate\n",
        "        hy = outgate * torch.tanh(cy)\n",
        "\n",
        "        return  hy, cy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Network \n",
        "class ourModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512, homework_step = 0 , DEVICE=\"\"):\n",
        "        super(ourModel, self).__init__()\n",
        "        self.DEVICE = DEVICE\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnetMod.resnet34(True, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.homework_step = homework_step\n",
        "        if self.homework_step == 1:\n",
        "          self.lstm_cell = MyLSTMCell(512, mem_size)\n",
        "        elif self.homework_step == 2:\n",
        "          self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "    def forward(self, inputVariable):\n",
        "        #Learning without Temporal information (mean)\n",
        "        if self.homework_step == 0:\n",
        "            video_level_features = torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE)\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(spatial_frame_feat.size(0), -1)\n",
        "                video_level_features = video_level_features + frame_feat\n",
        "\n",
        "            video_level_features = video_level_features / inputVariable.size(0)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (LSTM)\n",
        "        elif self.homework_step == 1:\n",
        "            state = ( torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE) ) \n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(state[1].size(0), -1)\n",
        "                state = self.lstm_cell(frame_feat, state)\n",
        "\n",
        "            video_level_features = state[1]\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (ConvLSTM)\n",
        "        elif self.homework_step == 2:\n",
        "            state = (torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE))\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                state = self.lstm_cell(spatial_frame_feat, state)\n",
        "            video_level_features = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru8vllrMbgvL"
      },
      "source": [
        "#Build Model - Loss - Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZe-ZbEL7z3x"
      },
      "source": [
        "#CUDA_LAUNCH_BLOCKING=1\n",
        "validate = True\n",
        "\n",
        "model = ourModel(num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE) #model\n",
        "\n",
        "#Train only the lstm cell and classifier\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "if homework_step > 0:\n",
        "    for params in model.lstm_cell.parameters():\n",
        "        params.requires_grad = True\n",
        "    model.lstm_cell.train(True)\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "model.classifier.train(True)\n",
        "\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/best_model_state_dict_rgb_split2.pth\", map_location=torch.device('cpu')), strict=True)\n",
        "\n",
        "\n",
        "#Loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Opt\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n",
        "#Scheduler\n",
        "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0MWgLingzhw"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uE2A9eHmtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876f9822-9448-448c-d9cc-e4a22ee3f32f"
      },
      "source": [
        "train_iter = 0\n",
        "val_iter = 0\n",
        "min_accuracy = 0\n",
        "\n",
        "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
        "val_samples = len(test_dataset) \n",
        "iterPerEpoch = len(train_loader)\n",
        "val_steps = len(val_loader)\n",
        "cudnn.benchmark\n",
        "model_checkpoint = \"model\" #name\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    \n",
        "    #blocks to train\n",
        "    if homework_step > 0:\n",
        "        model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        \n",
        "        # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        # feeds in model\n",
        "        output_label, _ = model(inputVariable)\n",
        "        \n",
        "        # compute loss \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        # backward loss and optimizer step \n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        \n",
        "        #compute the training accuracy \n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "    \n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "    print(Fore.BLACK + 'Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "                \n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "                \n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "\n",
        "print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n",
        "print(Fore.CYAN + \"Last Acc --> \", val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mTrain: Epoch = 1 | Loss = 4.824 | Accuracy = 1.250\n",
            "\u001b[32mVal: Epoch = 1 | Loss 4.128 | Accuracy = 6.034\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 2 | Loss = 4.530 | Accuracy = 4.062\n",
            "\u001b[32mVal: Epoch = 2 | Loss 4.076 | Accuracy = 7.759\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 3 | Loss = 4.500 | Accuracy = 5.312\n",
            "\u001b[32mVal: Epoch = 3 | Loss 4.002 | Accuracy = 10.345\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 4 | Loss = 4.462 | Accuracy = 2.812\n",
            "\u001b[32mVal: Epoch = 4 | Loss 3.941 | Accuracy = 10.345\n",
            "\u001b[30mTrain: Epoch = 5 | Loss = 4.390 | Accuracy = 5.312\n",
            "\u001b[32mVal: Epoch = 5 | Loss 3.877 | Accuracy = 11.207\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 6 | Loss = 4.305 | Accuracy = 3.125\n",
            "\u001b[32mVal: Epoch = 6 | Loss 3.823 | Accuracy = 12.069\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 7 | Loss = 4.237 | Accuracy = 4.688\n",
            "\u001b[32mVal: Epoch = 7 | Loss 3.782 | Accuracy = 10.345\n",
            "\u001b[30mTrain: Epoch = 8 | Loss = 4.307 | Accuracy = 5.312\n",
            "\u001b[32mVal: Epoch = 8 | Loss 3.748 | Accuracy = 12.069\n",
            "\u001b[30mTrain: Epoch = 9 | Loss = 4.233 | Accuracy = 5.312\n",
            "\u001b[32mVal: Epoch = 9 | Loss 3.717 | Accuracy = 16.379\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 10 | Loss = 4.023 | Accuracy = 7.500\n",
            "\u001b[32mVal: Epoch = 10 | Loss 3.685 | Accuracy = 13.793\n",
            "\u001b[30mTrain: Epoch = 11 | Loss = 3.968 | Accuracy = 7.500\n",
            "\u001b[32mVal: Epoch = 11 | Loss 3.656 | Accuracy = 12.069\n",
            "\u001b[30mTrain: Epoch = 12 | Loss = 4.002 | Accuracy = 8.750\n",
            "\u001b[32mVal: Epoch = 12 | Loss 3.621 | Accuracy = 15.517\n",
            "\u001b[30mTrain: Epoch = 13 | Loss = 3.935 | Accuracy = 10.000\n",
            "\u001b[32mVal: Epoch = 13 | Loss 3.593 | Accuracy = 17.241\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 14 | Loss = 3.924 | Accuracy = 7.812\n",
            "\u001b[32mVal: Epoch = 14 | Loss 3.551 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 15 | Loss = 3.866 | Accuracy = 8.438\n",
            "\u001b[32mVal: Epoch = 15 | Loss 3.516 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 16 | Loss = 3.905 | Accuracy = 9.688\n",
            "\u001b[32mVal: Epoch = 16 | Loss 3.485 | Accuracy = 18.966\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 17 | Loss = 3.846 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 17 | Loss 3.458 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 18 | Loss = 3.831 | Accuracy = 7.500\n",
            "\u001b[32mVal: Epoch = 18 | Loss 3.436 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 19 | Loss = 3.757 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 19 | Loss 3.412 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 20 | Loss = 3.759 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 20 | Loss 3.394 | Accuracy = 14.655\n",
            "\u001b[30mTrain: Epoch = 21 | Loss = 3.645 | Accuracy = 10.312\n",
            "\u001b[32mVal: Epoch = 21 | Loss 3.369 | Accuracy = 20.690\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 22 | Loss = 3.765 | Accuracy = 8.438\n",
            "\u001b[32mVal: Epoch = 22 | Loss 3.337 | Accuracy = 21.552\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 23 | Loss = 3.672 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 23 | Loss 3.316 | Accuracy = 22.414\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 24 | Loss = 3.687 | Accuracy = 10.000\n",
            "\u001b[32mVal: Epoch = 24 | Loss 3.283 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 25 | Loss = 3.776 | Accuracy = 10.312\n",
            "\u001b[32mVal: Epoch = 25 | Loss 3.259 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 26 | Loss = 3.625 | Accuracy = 11.562\n",
            "\u001b[32mVal: Epoch = 26 | Loss 3.256 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 27 | Loss = 3.546 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 27 | Loss 3.254 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 28 | Loss = 3.629 | Accuracy = 12.188\n",
            "\u001b[32mVal: Epoch = 28 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 29 | Loss = 3.680 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 29 | Loss 3.248 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 30 | Loss = 3.544 | Accuracy = 10.312\n",
            "\u001b[32mVal: Epoch = 30 | Loss 3.245 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 31 | Loss = 3.582 | Accuracy = 12.188\n",
            "\u001b[32mVal: Epoch = 31 | Loss 3.242 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 32 | Loss = 3.584 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 32 | Loss 3.240 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 33 | Loss = 3.606 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 33 | Loss 3.237 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 34 | Loss = 3.634 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 34 | Loss 3.234 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 35 | Loss = 3.542 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 35 | Loss 3.233 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 36 | Loss = 3.583 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 36 | Loss 3.232 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 37 | Loss = 3.621 | Accuracy = 10.000\n",
            "\u001b[32mVal: Epoch = 37 | Loss 3.231 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 38 | Loss = 3.645 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 38 | Loss 3.230 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 39 | Loss = 3.550 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 39 | Loss 3.228 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 40 | Loss = 3.631 | Accuracy = 10.625\n",
            "\u001b[32mVal: Epoch = 40 | Loss 3.226 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 41 | Loss = 3.620 | Accuracy = 10.625\n",
            "\u001b[32mVal: Epoch = 41 | Loss 3.224 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 42 | Loss = 3.636 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 42 | Loss 3.223 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 43 | Loss = 3.511 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 43 | Loss 3.222 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 44 | Loss = 3.671 | Accuracy = 8.750\n",
            "\u001b[32mVal: Epoch = 44 | Loss 3.222 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 45 | Loss = 3.532 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 45 | Loss 3.221 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 46 | Loss = 3.691 | Accuracy = 7.812\n",
            "\u001b[32mVal: Epoch = 46 | Loss 3.219 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 47 | Loss = 3.518 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 47 | Loss 3.217 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 48 | Loss = 3.548 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 48 | Loss 3.215 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 49 | Loss = 3.521 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 49 | Loss 3.212 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 50 | Loss = 3.523 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 50 | Loss 3.210 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 51 | Loss = 3.568 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 51 | Loss 3.208 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 52 | Loss = 3.547 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 52 | Loss 3.206 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 53 | Loss = 3.582 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 53 | Loss 3.204 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 54 | Loss = 3.522 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 54 | Loss 3.203 | Accuracy = 23.276\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 55 | Loss = 3.509 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 55 | Loss 3.201 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 56 | Loss = 3.592 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 56 | Loss 3.199 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 57 | Loss = 3.547 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 57 | Loss 3.197 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 58 | Loss = 3.474 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 58 | Loss 3.196 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 59 | Loss = 3.597 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 59 | Loss 3.193 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 60 | Loss = 3.594 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 60 | Loss 3.190 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 61 | Loss = 3.494 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 61 | Loss 3.188 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 62 | Loss = 3.509 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 62 | Loss 3.187 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 63 | Loss = 3.490 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 63 | Loss 3.184 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 64 | Loss = 3.653 | Accuracy = 9.375\n",
            "\u001b[32mVal: Epoch = 64 | Loss 3.181 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 65 | Loss = 3.614 | Accuracy = 12.188\n",
            "\u001b[32mVal: Epoch = 65 | Loss 3.179 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 66 | Loss = 3.523 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 66 | Loss 3.177 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 67 | Loss = 3.476 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 67 | Loss 3.176 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 68 | Loss = 3.597 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 68 | Loss 3.174 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 69 | Loss = 3.470 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 69 | Loss 3.174 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 70 | Loss = 3.543 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 70 | Loss 3.173 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 71 | Loss = 3.431 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 71 | Loss 3.171 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 72 | Loss = 3.451 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 72 | Loss 3.169 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 73 | Loss = 3.463 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 73 | Loss 3.167 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 74 | Loss = 3.498 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 74 | Loss 3.165 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 75 | Loss = 3.488 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 75 | Loss 3.162 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 76 | Loss = 3.486 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 76 | Loss 3.162 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 77 | Loss = 3.557 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 77 | Loss 3.162 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 78 | Loss = 3.463 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 78 | Loss 3.162 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 79 | Loss = 3.561 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 79 | Loss 3.161 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 80 | Loss = 3.458 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 80 | Loss 3.161 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 81 | Loss = 3.393 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 81 | Loss 3.161 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 82 | Loss = 3.446 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 82 | Loss 3.161 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 83 | Loss = 3.411 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 83 | Loss 3.161 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 84 | Loss = 3.491 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 84 | Loss 3.161 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 85 | Loss = 3.536 | Accuracy = 10.312\n",
            "\u001b[32mVal: Epoch = 85 | Loss 3.160 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 86 | Loss = 3.470 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 86 | Loss 3.160 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 87 | Loss = 3.460 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 87 | Loss 3.160 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 88 | Loss = 3.482 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 88 | Loss 3.160 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 89 | Loss = 3.499 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 89 | Loss 3.160 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 90 | Loss = 3.546 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 90 | Loss 3.160 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 91 | Loss = 3.514 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 91 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 92 | Loss = 3.387 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 92 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 93 | Loss = 3.473 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 93 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 94 | Loss = 3.509 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 94 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 95 | Loss = 3.405 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 95 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 96 | Loss = 3.441 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 96 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 97 | Loss = 3.416 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 97 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 98 | Loss = 3.525 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 98 | Loss 3.159 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 99 | Loss = 3.546 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 99 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 100 | Loss = 3.497 | Accuracy = 11.562\n",
            "\u001b[32mVal: Epoch = 100 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 101 | Loss = 3.513 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 101 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 102 | Loss = 3.536 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 102 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 103 | Loss = 3.440 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 103 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 104 | Loss = 3.556 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 104 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 105 | Loss = 3.390 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 105 | Loss 3.158 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 106 | Loss = 3.492 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 106 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 107 | Loss = 3.479 | Accuracy = 11.562\n",
            "\u001b[32mVal: Epoch = 107 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 108 | Loss = 3.442 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 108 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 109 | Loss = 3.538 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 109 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 110 | Loss = 3.513 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 110 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 111 | Loss = 3.489 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 111 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 112 | Loss = 3.542 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 112 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 113 | Loss = 3.458 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 113 | Loss 3.157 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 114 | Loss = 3.486 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 114 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 115 | Loss = 3.582 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 115 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 116 | Loss = 3.532 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 116 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 117 | Loss = 3.480 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 117 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 118 | Loss = 3.543 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 118 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 119 | Loss = 3.607 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 119 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 120 | Loss = 3.513 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 120 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 121 | Loss = 3.528 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 121 | Loss 3.156 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 122 | Loss = 3.551 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 122 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 123 | Loss = 3.522 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 123 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 124 | Loss = 3.438 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 124 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 125 | Loss = 3.430 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 125 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 126 | Loss = 3.459 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 126 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 127 | Loss = 3.487 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 127 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 128 | Loss = 3.515 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 128 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 129 | Loss = 3.494 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 129 | Loss 3.155 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 130 | Loss = 3.540 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 130 | Loss 3.154 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 131 | Loss = 3.564 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 131 | Loss 3.154 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 132 | Loss = 3.583 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 132 | Loss 3.154 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 133 | Loss = 3.523 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 133 | Loss 3.154 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 134 | Loss = 3.424 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 134 | Loss 3.154 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 135 | Loss = 3.512 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 135 | Loss 3.154 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 136 | Loss = 3.467 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 136 | Loss 3.153 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 137 | Loss = 3.503 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 137 | Loss 3.153 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 138 | Loss = 3.465 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 138 | Loss 3.153 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 139 | Loss = 3.465 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 139 | Loss 3.153 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 140 | Loss = 3.543 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 140 | Loss 3.153 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 141 | Loss = 3.347 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 141 | Loss 3.152 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 142 | Loss = 3.494 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 142 | Loss 3.152 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 143 | Loss = 3.501 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 143 | Loss 3.152 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 144 | Loss = 3.442 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 144 | Loss 3.152 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 145 | Loss = 3.429 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 145 | Loss 3.152 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 146 | Loss = 3.430 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 146 | Loss 3.152 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 147 | Loss = 3.473 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 147 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 148 | Loss = 3.464 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 148 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 149 | Loss = 3.490 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 149 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 150 | Loss = 3.485 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 150 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 151 | Loss = 3.505 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 151 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 152 | Loss = 3.475 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 152 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 153 | Loss = 3.504 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 153 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 154 | Loss = 3.374 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 154 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 155 | Loss = 3.437 | Accuracy = 11.562\n",
            "\u001b[32mVal: Epoch = 155 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 156 | Loss = 3.483 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 156 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 157 | Loss = 3.492 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 157 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 158 | Loss = 3.467 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 158 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 159 | Loss = 3.546 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 159 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 160 | Loss = 3.482 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 160 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 161 | Loss = 3.493 | Accuracy = 12.188\n",
            "\u001b[32mVal: Epoch = 161 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 162 | Loss = 3.529 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 162 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 163 | Loss = 3.410 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 163 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 164 | Loss = 3.469 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 164 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 165 | Loss = 3.534 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 165 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 166 | Loss = 3.573 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 166 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 167 | Loss = 3.414 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 167 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 168 | Loss = 3.537 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 168 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 169 | Loss = 3.527 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 169 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 170 | Loss = 3.587 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 170 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 171 | Loss = 3.489 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 171 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 172 | Loss = 3.453 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 172 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 173 | Loss = 3.494 | Accuracy = 12.188\n",
            "\u001b[32mVal: Epoch = 173 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 174 | Loss = 3.440 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 174 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 175 | Loss = 3.493 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 175 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 176 | Loss = 3.608 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 176 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 177 | Loss = 3.573 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 177 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 178 | Loss = 3.411 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 178 | Loss 3.151 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 179 | Loss = 3.404 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 179 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 180 | Loss = 3.312 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 180 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 181 | Loss = 3.470 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 181 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 182 | Loss = 3.520 | Accuracy = 10.938\n",
            "\u001b[32mVal: Epoch = 182 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 183 | Loss = 3.450 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 183 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 184 | Loss = 3.473 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 184 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 185 | Loss = 3.459 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 185 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 186 | Loss = 3.415 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 186 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 187 | Loss = 3.508 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 187 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 188 | Loss = 3.477 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 188 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 189 | Loss = 3.538 | Accuracy = 12.812\n",
            "\u001b[32mVal: Epoch = 189 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 190 | Loss = 3.376 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 190 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 191 | Loss = 3.546 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 191 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 192 | Loss = 3.436 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 192 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 193 | Loss = 3.502 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 193 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 194 | Loss = 3.413 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 194 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 195 | Loss = 3.463 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 195 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 196 | Loss = 3.508 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 196 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 197 | Loss = 3.431 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 197 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 198 | Loss = 3.466 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 198 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 199 | Loss = 3.465 | Accuracy = 17.500\n",
            "\u001b[32mVal: Epoch = 199 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 200 | Loss = 3.497 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 200 | Loss 3.150 | Accuracy = 23.276\n",
            "\u001b[36mBest Acc -->  23.275862068965516\n",
            "\u001b[36mLast Acc -->  23.275862068965516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLs_T2Qd0kc"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqK1ExB0cl8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec055bd6-1a5a-4fd0-88d7-d3fab8d9b230"
      },
      "source": [
        "model.train(False)\n",
        "val_loss_epoch = 0\n",
        "numCorr = 0\n",
        "val_iter = 0\n",
        "val_samples = len(test_dataset) \n",
        "val_steps = len(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for j, (inputs, targets) in enumerate(val_loader):\n",
        "        val_iter += 1\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "        \n",
        "        output_label, _ = model(inputVariable)\n",
        "        val_loss = loss_fn(output_label, labelVariable)\n",
        "        val_loss_step = val_loss.data.item()\n",
        "        val_loss_epoch += val_loss_step\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        \n",
        "    val_accuracy = (numCorr / val_samples) * 100\n",
        "    avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "print('Loss {:.3f} | Accuracy = {:.3f}'.format(avg_val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 1.817 | Accuracy = 45.690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9BxL8zeBfv"
      },
      "source": [
        "#**Learning with Temporal information** (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mk3HJWjxzOg",
        "outputId": "a0b26b0f-20a6-40be-836b-17dfcc3ea10e"
      },
      "source": [
        "train_iter = 0\n",
        "val_iter = 0\n",
        "min_accuracy = 0\n",
        "\n",
        "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
        "val_samples = len(test_dataset) \n",
        "iterPerEpoch = len(train_loader)\n",
        "val_steps = len(val_loader)\n",
        "cudnn.benchmark\n",
        "model_checkpoint = \"model-LSTMonly\" #name\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    \n",
        "    #blocks to train\n",
        "    if homework_step > 0:\n",
        "        model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        \n",
        "        # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        # feeds in model\n",
        "        output_label, _ = model(inputVariable)\n",
        "        \n",
        "        # compute loss \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        # backward loss and optimizer step \n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        \n",
        "        #compute the training accuracy \n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "    \n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "    print(Fore.BLACK + 'Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "                \n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "                \n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "\n",
        "print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n",
        "print(Fore.CYAN + \"Last Acc --> \", val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mTrain: Epoch = 1 | Loss = 4.878 | Accuracy = 0.938\n",
            "\u001b[32mVal: Epoch = 1 | Loss 4.166 | Accuracy = 4.310\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 2 | Loss = 4.612 | Accuracy = 3.750\n",
            "\u001b[32mVal: Epoch = 2 | Loss 4.020 | Accuracy = 6.897\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 3 | Loss = 4.313 | Accuracy = 5.312\n",
            "\u001b[32mVal: Epoch = 3 | Loss 3.942 | Accuracy = 6.034\n",
            "\u001b[30mTrain: Epoch = 4 | Loss = 4.300 | Accuracy = 5.625\n",
            "\u001b[32mVal: Epoch = 4 | Loss 3.875 | Accuracy = 7.759\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 5 | Loss = 4.428 | Accuracy = 4.375\n",
            "\u001b[32mVal: Epoch = 5 | Loss 3.824 | Accuracy = 8.621\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 6 | Loss = 4.206 | Accuracy = 5.000\n",
            "\u001b[32mVal: Epoch = 6 | Loss 3.796 | Accuracy = 8.621\n",
            "\u001b[30mTrain: Epoch = 7 | Loss = 4.178 | Accuracy = 5.000\n",
            "\u001b[32mVal: Epoch = 7 | Loss 3.759 | Accuracy = 7.759\n",
            "\u001b[30mTrain: Epoch = 8 | Loss = 4.108 | Accuracy = 7.500\n",
            "\u001b[32mVal: Epoch = 8 | Loss 3.717 | Accuracy = 9.483\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 9 | Loss = 4.108 | Accuracy = 6.875\n",
            "\u001b[32mVal: Epoch = 9 | Loss 3.684 | Accuracy = 9.483\n",
            "\u001b[30mTrain: Epoch = 10 | Loss = 4.138 | Accuracy = 6.875\n",
            "\u001b[32mVal: Epoch = 10 | Loss 3.663 | Accuracy = 12.069\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 11 | Loss = 3.868 | Accuracy = 8.438\n",
            "\u001b[32mVal: Epoch = 11 | Loss 3.655 | Accuracy = 13.793\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 12 | Loss = 3.974 | Accuracy = 9.375\n",
            "\u001b[32mVal: Epoch = 12 | Loss 3.632 | Accuracy = 14.655\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 13 | Loss = 4.072 | Accuracy = 6.875\n",
            "\u001b[32mVal: Epoch = 13 | Loss 3.602 | Accuracy = 16.379\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 14 | Loss = 3.776 | Accuracy = 9.688\n",
            "\u001b[32mVal: Epoch = 14 | Loss 3.580 | Accuracy = 17.241\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 15 | Loss = 3.784 | Accuracy = 8.125\n",
            "\u001b[32mVal: Epoch = 15 | Loss 3.548 | Accuracy = 18.103\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 16 | Loss = 3.721 | Accuracy = 10.312\n",
            "\u001b[32mVal: Epoch = 16 | Loss 3.524 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 17 | Loss = 3.712 | Accuracy = 9.375\n",
            "\u001b[32mVal: Epoch = 17 | Loss 3.505 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 18 | Loss = 3.767 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 18 | Loss 3.472 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 19 | Loss = 3.659 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 19 | Loss 3.445 | Accuracy = 19.828\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 20 | Loss = 3.597 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 20 | Loss 3.425 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 21 | Loss = 3.473 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 21 | Loss 3.420 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 22 | Loss = 3.585 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 22 | Loss 3.406 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 23 | Loss = 3.530 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 23 | Loss 3.393 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 24 | Loss = 3.553 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 24 | Loss 3.375 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 25 | Loss = 3.467 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 25 | Loss 3.355 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 26 | Loss = 3.494 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 26 | Loss 3.354 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 27 | Loss = 3.403 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 27 | Loss 3.352 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 28 | Loss = 3.352 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 28 | Loss 3.351 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 29 | Loss = 3.456 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 29 | Loss 3.349 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 30 | Loss = 3.400 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 30 | Loss 3.347 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 31 | Loss = 3.372 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 31 | Loss 3.344 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 32 | Loss = 3.374 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 32 | Loss 3.343 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 33 | Loss = 3.405 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 33 | Loss 3.341 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 34 | Loss = 3.329 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 34 | Loss 3.339 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 35 | Loss = 3.403 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 35 | Loss 3.337 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 36 | Loss = 3.493 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 36 | Loss 3.334 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 37 | Loss = 3.277 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 37 | Loss 3.331 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 38 | Loss = 3.359 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 38 | Loss 3.328 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 39 | Loss = 3.400 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 39 | Loss 3.326 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 40 | Loss = 3.335 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 40 | Loss 3.323 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 41 | Loss = 3.512 | Accuracy = 14.062\n",
            "\u001b[32mVal: Epoch = 41 | Loss 3.321 | Accuracy = 16.379\n",
            "\u001b[30mTrain: Epoch = 42 | Loss = 3.278 | Accuracy = 21.562\n",
            "\u001b[32mVal: Epoch = 42 | Loss 3.319 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 43 | Loss = 3.444 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 43 | Loss 3.318 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 44 | Loss = 3.396 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 44 | Loss 3.316 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 45 | Loss = 3.372 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 45 | Loss 3.313 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 46 | Loss = 3.338 | Accuracy = 22.188\n",
            "\u001b[32mVal: Epoch = 46 | Loss 3.311 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 47 | Loss = 3.400 | Accuracy = 13.750\n",
            "\u001b[32mVal: Epoch = 47 | Loss 3.309 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 48 | Loss = 3.405 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 48 | Loss 3.307 | Accuracy = 17.241\n",
            "\u001b[30mTrain: Epoch = 49 | Loss = 3.364 | Accuracy = 17.500\n",
            "\u001b[32mVal: Epoch = 49 | Loss 3.306 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 50 | Loss = 3.371 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 50 | Loss 3.305 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 51 | Loss = 3.287 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 51 | Loss 3.304 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 52 | Loss = 3.417 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 52 | Loss 3.303 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 53 | Loss = 3.401 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 53 | Loss 3.302 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 54 | Loss = 3.302 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 54 | Loss 3.300 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 55 | Loss = 3.261 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 55 | Loss 3.297 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 56 | Loss = 3.276 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 56 | Loss 3.294 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 57 | Loss = 3.281 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 57 | Loss 3.292 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 58 | Loss = 3.299 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 58 | Loss 3.290 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 59 | Loss = 3.211 | Accuracy = 21.875\n",
            "\u001b[32mVal: Epoch = 59 | Loss 3.288 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 60 | Loss = 3.307 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 60 | Loss 3.287 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 61 | Loss = 3.272 | Accuracy = 21.250\n",
            "\u001b[32mVal: Epoch = 61 | Loss 3.287 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 62 | Loss = 3.300 | Accuracy = 17.500\n",
            "\u001b[32mVal: Epoch = 62 | Loss 3.287 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 63 | Loss = 3.312 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 63 | Loss 3.286 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 64 | Loss = 3.293 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 64 | Loss 3.285 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 65 | Loss = 3.246 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 65 | Loss 3.283 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 66 | Loss = 3.211 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 66 | Loss 3.282 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 67 | Loss = 3.324 | Accuracy = 15.313\n",
            "\u001b[32mVal: Epoch = 67 | Loss 3.279 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 68 | Loss = 3.322 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 68 | Loss 3.276 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 69 | Loss = 3.272 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 69 | Loss 3.274 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 70 | Loss = 3.320 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 70 | Loss 3.272 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 71 | Loss = 3.327 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 71 | Loss 3.269 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 72 | Loss = 3.204 | Accuracy = 21.562\n",
            "\u001b[32mVal: Epoch = 72 | Loss 3.266 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 73 | Loss = 3.319 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 73 | Loss 3.262 | Accuracy = 20.690\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 74 | Loss = 3.290 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 74 | Loss 3.259 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 75 | Loss = 3.312 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 75 | Loss 3.257 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 76 | Loss = 3.278 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 76 | Loss 3.257 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 77 | Loss = 3.175 | Accuracy = 22.500\n",
            "\u001b[32mVal: Epoch = 77 | Loss 3.257 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 78 | Loss = 3.326 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 78 | Loss 3.256 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 79 | Loss = 3.276 | Accuracy = 17.500\n",
            "\u001b[32mVal: Epoch = 79 | Loss 3.256 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 80 | Loss = 3.263 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 80 | Loss 3.256 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 81 | Loss = 3.215 | Accuracy = 22.188\n",
            "\u001b[32mVal: Epoch = 81 | Loss 3.256 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 82 | Loss = 3.211 | Accuracy = 21.250\n",
            "\u001b[32mVal: Epoch = 82 | Loss 3.255 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 83 | Loss = 3.234 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 83 | Loss 3.255 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 84 | Loss = 3.351 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 84 | Loss 3.255 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 85 | Loss = 3.212 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 85 | Loss 3.255 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 86 | Loss = 3.296 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 86 | Loss 3.255 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 87 | Loss = 3.316 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 87 | Loss 3.255 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 88 | Loss = 3.298 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 88 | Loss 3.254 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 89 | Loss = 3.248 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 89 | Loss 3.254 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 90 | Loss = 3.301 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 90 | Loss 3.254 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 91 | Loss = 3.309 | Accuracy = 17.500\n",
            "\u001b[32mVal: Epoch = 91 | Loss 3.254 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 92 | Loss = 3.290 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 92 | Loss 3.253 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 93 | Loss = 3.272 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 93 | Loss 3.253 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 94 | Loss = 3.356 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 94 | Loss 3.253 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 95 | Loss = 3.207 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 95 | Loss 3.253 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 96 | Loss = 3.359 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 96 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 97 | Loss = 3.177 | Accuracy = 22.188\n",
            "\u001b[32mVal: Epoch = 97 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 98 | Loss = 3.278 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 98 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 99 | Loss = 3.339 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 99 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 100 | Loss = 3.272 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 100 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 101 | Loss = 3.220 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 101 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 102 | Loss = 3.314 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 102 | Loss 3.252 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 103 | Loss = 3.210 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 103 | Loss 3.251 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 104 | Loss = 3.384 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 104 | Loss 3.251 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 105 | Loss = 3.180 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 105 | Loss 3.251 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 106 | Loss = 3.308 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 106 | Loss 3.251 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 107 | Loss = 3.310 | Accuracy = 16.875\n",
            "\u001b[32mVal: Epoch = 107 | Loss 3.251 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 108 | Loss = 3.309 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 108 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 109 | Loss = 3.277 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 109 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 110 | Loss = 3.188 | Accuracy = 22.188\n",
            "\u001b[32mVal: Epoch = 110 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 111 | Loss = 3.216 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 111 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 112 | Loss = 3.239 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 112 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 113 | Loss = 3.168 | Accuracy = 21.875\n",
            "\u001b[32mVal: Epoch = 113 | Loss 3.250 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 114 | Loss = 3.318 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 114 | Loss 3.249 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 115 | Loss = 3.266 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 115 | Loss 3.249 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 116 | Loss = 3.167 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 116 | Loss 3.249 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 117 | Loss = 3.304 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 117 | Loss 3.248 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 118 | Loss = 3.221 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 118 | Loss 3.248 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 119 | Loss = 3.225 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 119 | Loss 3.248 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 120 | Loss = 3.177 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 120 | Loss 3.248 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 121 | Loss = 3.252 | Accuracy = 21.250\n",
            "\u001b[32mVal: Epoch = 121 | Loss 3.247 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 122 | Loss = 3.201 | Accuracy = 21.562\n",
            "\u001b[32mVal: Epoch = 122 | Loss 3.247 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 123 | Loss = 3.367 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 123 | Loss 3.247 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 124 | Loss = 3.411 | Accuracy = 14.688\n",
            "\u001b[32mVal: Epoch = 124 | Loss 3.247 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 125 | Loss = 3.273 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 125 | Loss 3.247 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 126 | Loss = 3.327 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 126 | Loss 3.247 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 127 | Loss = 3.227 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 127 | Loss 3.246 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 128 | Loss = 3.206 | Accuracy = 22.188\n",
            "\u001b[32mVal: Epoch = 128 | Loss 3.246 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 129 | Loss = 3.173 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 129 | Loss 3.246 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 130 | Loss = 3.289 | Accuracy = 20.938\n",
            "\u001b[32mVal: Epoch = 130 | Loss 3.246 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 131 | Loss = 3.265 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 131 | Loss 3.245 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 132 | Loss = 3.126 | Accuracy = 21.875\n",
            "\u001b[32mVal: Epoch = 132 | Loss 3.245 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 133 | Loss = 3.224 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 133 | Loss 3.245 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 134 | Loss = 3.246 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 134 | Loss 3.245 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 135 | Loss = 3.260 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 135 | Loss 3.244 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 136 | Loss = 3.233 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 136 | Loss 3.244 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 137 | Loss = 3.161 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 137 | Loss 3.243 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 138 | Loss = 3.183 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 138 | Loss 3.243 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 139 | Loss = 3.254 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 139 | Loss 3.243 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 140 | Loss = 3.346 | Accuracy = 15.000\n",
            "\u001b[32mVal: Epoch = 140 | Loss 3.243 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 141 | Loss = 3.238 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 141 | Loss 3.242 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 142 | Loss = 3.243 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 142 | Loss 3.242 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 143 | Loss = 3.231 | Accuracy = 21.875\n",
            "\u001b[32mVal: Epoch = 143 | Loss 3.242 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 144 | Loss = 3.204 | Accuracy = 20.938\n",
            "\u001b[32mVal: Epoch = 144 | Loss 3.242 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 145 | Loss = 3.303 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 145 | Loss 3.242 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 146 | Loss = 3.222 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 146 | Loss 3.242 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 147 | Loss = 3.272 | Accuracy = 17.500\n",
            "\u001b[32mVal: Epoch = 147 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 148 | Loss = 3.270 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 148 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 149 | Loss = 3.166 | Accuracy = 22.500\n",
            "\u001b[32mVal: Epoch = 149 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 150 | Loss = 3.154 | Accuracy = 21.562\n",
            "\u001b[32mVal: Epoch = 150 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 151 | Loss = 3.156 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 151 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 152 | Loss = 3.321 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 152 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 153 | Loss = 3.219 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 153 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 154 | Loss = 3.208 | Accuracy = 22.812\n",
            "\u001b[32mVal: Epoch = 154 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 155 | Loss = 3.114 | Accuracy = 24.375\n",
            "\u001b[32mVal: Epoch = 155 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 156 | Loss = 3.261 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 156 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 157 | Loss = 3.185 | Accuracy = 23.438\n",
            "\u001b[32mVal: Epoch = 157 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 158 | Loss = 3.169 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 158 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 159 | Loss = 3.175 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 159 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 160 | Loss = 3.284 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 160 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 161 | Loss = 3.224 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 161 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 162 | Loss = 3.272 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 162 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 163 | Loss = 3.188 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 163 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 164 | Loss = 3.188 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 164 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 165 | Loss = 3.275 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 165 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 166 | Loss = 3.181 | Accuracy = 19.375\n",
            "\u001b[32mVal: Epoch = 166 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 167 | Loss = 3.216 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 167 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 168 | Loss = 3.297 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 168 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 169 | Loss = 3.191 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 169 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 170 | Loss = 3.297 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 170 | Loss 3.241 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 171 | Loss = 3.269 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 171 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 172 | Loss = 3.127 | Accuracy = 24.062\n",
            "\u001b[32mVal: Epoch = 172 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 173 | Loss = 3.191 | Accuracy = 21.250\n",
            "\u001b[32mVal: Epoch = 173 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 174 | Loss = 3.249 | Accuracy = 22.500\n",
            "\u001b[32mVal: Epoch = 174 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 175 | Loss = 3.352 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 175 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 176 | Loss = 3.172 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 176 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 177 | Loss = 3.272 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 177 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 178 | Loss = 3.185 | Accuracy = 20.312\n",
            "\u001b[32mVal: Epoch = 178 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 179 | Loss = 3.220 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 179 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 180 | Loss = 3.227 | Accuracy = 16.250\n",
            "\u001b[32mVal: Epoch = 180 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 181 | Loss = 3.241 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 181 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 182 | Loss = 3.215 | Accuracy = 22.500\n",
            "\u001b[32mVal: Epoch = 182 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 183 | Loss = 3.287 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 183 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 184 | Loss = 3.266 | Accuracy = 18.125\n",
            "\u001b[32mVal: Epoch = 184 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 185 | Loss = 3.123 | Accuracy = 20.938\n",
            "\u001b[32mVal: Epoch = 185 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 186 | Loss = 3.151 | Accuracy = 19.688\n",
            "\u001b[32mVal: Epoch = 186 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 187 | Loss = 3.348 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 187 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 188 | Loss = 3.190 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 188 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 189 | Loss = 3.274 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 189 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 190 | Loss = 3.125 | Accuracy = 20.938\n",
            "\u001b[32mVal: Epoch = 190 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 191 | Loss = 3.237 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 191 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 192 | Loss = 3.203 | Accuracy = 21.250\n",
            "\u001b[32mVal: Epoch = 192 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 193 | Loss = 3.172 | Accuracy = 21.250\n",
            "\u001b[32mVal: Epoch = 193 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 194 | Loss = 3.343 | Accuracy = 19.375\n",
            "\u001b[32mVal: Epoch = 194 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 195 | Loss = 3.202 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 195 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 196 | Loss = 3.234 | Accuracy = 21.562\n",
            "\u001b[32mVal: Epoch = 196 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 197 | Loss = 3.186 | Accuracy = 18.750\n",
            "\u001b[32mVal: Epoch = 197 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 198 | Loss = 3.278 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 198 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 199 | Loss = 3.266 | Accuracy = 17.812\n",
            "\u001b[32mVal: Epoch = 199 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 200 | Loss = 3.138 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 200 | Loss 3.240 | Accuracy = 19.828\n",
            "\u001b[36mBest Acc -->  20.689655172413794\n",
            "\u001b[36mLast Acc -->  19.82758620689655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-qHYgnyf_wn"
      },
      "source": [
        "#**Learning with Spatio-Temporal information** (ConvLSTM)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqCLGP11Gl1O",
        "outputId": "4bcb2701-4b12-447c-dd25-b8a925f8d3d4"
      },
      "source": [
        "train_iter = 0\n",
        "val_iter = 0\n",
        "min_accuracy = 0\n",
        "\n",
        "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
        "val_samples = len(test_dataset) \n",
        "iterPerEpoch = len(train_loader)\n",
        "val_steps = len(val_loader)\n",
        "cudnn.benchmark\n",
        "model_checkpoint = \"model-ConvLSTM\" #name\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    \n",
        "    #blocks to train\n",
        "    if homework_step > 0:\n",
        "        model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        \n",
        "        # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        # feeds in model\n",
        "        output_label, _ = model(inputVariable)\n",
        "        \n",
        "        # compute loss \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        # backward loss and optimizer step \n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        \n",
        "        #compute the training accuracy \n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "    \n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "    print(Fore.BLACK + 'Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "                \n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "                \n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "\n",
        "print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n",
        "print(Fore.CYAN + \"Last Acc --> \", val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mTrain: Epoch = 1 | Loss = 4.308 | Accuracy = 11.250\n",
            "\u001b[32mVal: Epoch = 1 | Loss 2.785 | Accuracy = 24.138\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 2 | Loss = 3.461 | Accuracy = 15.625\n",
            "\u001b[32mVal: Epoch = 2 | Loss 2.788 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 3 | Loss = 3.151 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 3 | Loss 2.473 | Accuracy = 27.586\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 4 | Loss = 2.863 | Accuracy = 20.625\n",
            "\u001b[32mVal: Epoch = 4 | Loss 2.449 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 5 | Loss = 2.721 | Accuracy = 24.375\n",
            "\u001b[32mVal: Epoch = 5 | Loss 2.314 | Accuracy = 36.207\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 6 | Loss = 2.602 | Accuracy = 28.750\n",
            "\u001b[32mVal: Epoch = 6 | Loss 2.350 | Accuracy = 31.897\n",
            "\u001b[30mTrain: Epoch = 7 | Loss = 2.631 | Accuracy = 28.438\n",
            "\u001b[32mVal: Epoch = 7 | Loss 2.207 | Accuracy = 36.207\n",
            "\u001b[30mTrain: Epoch = 8 | Loss = 2.503 | Accuracy = 28.750\n",
            "\u001b[32mVal: Epoch = 8 | Loss 2.196 | Accuracy = 36.207\n",
            "\u001b[30mTrain: Epoch = 9 | Loss = 2.403 | Accuracy = 29.688\n",
            "\u001b[32mVal: Epoch = 9 | Loss 2.201 | Accuracy = 36.207\n",
            "\u001b[30mTrain: Epoch = 10 | Loss = 2.462 | Accuracy = 30.312\n",
            "\u001b[32mVal: Epoch = 10 | Loss 2.150 | Accuracy = 32.759\n",
            "\u001b[30mTrain: Epoch = 11 | Loss = 2.341 | Accuracy = 32.812\n",
            "\u001b[32mVal: Epoch = 11 | Loss 2.165 | Accuracy = 42.241\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 12 | Loss = 2.294 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 12 | Loss 2.146 | Accuracy = 37.069\n",
            "\u001b[30mTrain: Epoch = 13 | Loss = 2.308 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 13 | Loss 2.083 | Accuracy = 43.966\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 14 | Loss = 2.245 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 14 | Loss 2.115 | Accuracy = 37.069\n",
            "\u001b[30mTrain: Epoch = 15 | Loss = 2.195 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 15 | Loss 2.143 | Accuracy = 37.069\n",
            "\u001b[30mTrain: Epoch = 16 | Loss = 2.191 | Accuracy = 36.250\n",
            "\u001b[32mVal: Epoch = 16 | Loss 2.074 | Accuracy = 44.828\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 17 | Loss = 2.201 | Accuracy = 36.875\n",
            "\u001b[32mVal: Epoch = 17 | Loss 2.089 | Accuracy = 42.241\n",
            "\u001b[30mTrain: Epoch = 18 | Loss = 2.188 | Accuracy = 38.125\n",
            "\u001b[32mVal: Epoch = 18 | Loss 2.084 | Accuracy = 36.207\n",
            "\u001b[30mTrain: Epoch = 19 | Loss = 2.065 | Accuracy = 37.188\n",
            "\u001b[32mVal: Epoch = 19 | Loss 2.013 | Accuracy = 40.517\n",
            "\u001b[30mTrain: Epoch = 20 | Loss = 2.033 | Accuracy = 41.875\n",
            "\u001b[32mVal: Epoch = 20 | Loss 2.047 | Accuracy = 43.103\n",
            "\u001b[30mTrain: Epoch = 21 | Loss = 1.977 | Accuracy = 42.188\n",
            "\u001b[32mVal: Epoch = 21 | Loss 1.994 | Accuracy = 44.828\n",
            "\u001b[30mTrain: Epoch = 22 | Loss = 2.013 | Accuracy = 39.375\n",
            "\u001b[32mVal: Epoch = 22 | Loss 2.032 | Accuracy = 42.241\n",
            "\u001b[30mTrain: Epoch = 23 | Loss = 1.985 | Accuracy = 42.188\n",
            "\u001b[32mVal: Epoch = 23 | Loss 2.037 | Accuracy = 43.103\n",
            "\u001b[30mTrain: Epoch = 24 | Loss = 1.985 | Accuracy = 39.688\n",
            "\u001b[32mVal: Epoch = 24 | Loss 2.026 | Accuracy = 41.379\n",
            "\u001b[30mTrain: Epoch = 25 | Loss = 1.968 | Accuracy = 40.625\n",
            "\u001b[32mVal: Epoch = 25 | Loss 2.002 | Accuracy = 41.379\n",
            "\u001b[30mTrain: Epoch = 26 | Loss = 1.919 | Accuracy = 45.000\n",
            "\u001b[32mVal: Epoch = 26 | Loss 1.982 | Accuracy = 43.103\n",
            "\u001b[30mTrain: Epoch = 27 | Loss = 1.943 | Accuracy = 44.062\n",
            "\u001b[32mVal: Epoch = 27 | Loss 1.978 | Accuracy = 43.966\n",
            "\u001b[30mTrain: Epoch = 28 | Loss = 1.778 | Accuracy = 47.188\n",
            "\u001b[32mVal: Epoch = 28 | Loss 1.960 | Accuracy = 43.966\n",
            "\u001b[30mTrain: Epoch = 29 | Loss = 1.807 | Accuracy = 47.812\n",
            "\u001b[32mVal: Epoch = 29 | Loss 1.941 | Accuracy = 46.552\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 30 | Loss = 1.726 | Accuracy = 47.812\n",
            "\u001b[32mVal: Epoch = 30 | Loss 1.941 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 31 | Loss = 1.765 | Accuracy = 50.000\n",
            "\u001b[32mVal: Epoch = 31 | Loss 1.950 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 32 | Loss = 1.831 | Accuracy = 47.188\n",
            "\u001b[32mVal: Epoch = 32 | Loss 1.947 | Accuracy = 44.828\n",
            "\u001b[30mTrain: Epoch = 33 | Loss = 1.708 | Accuracy = 49.062\n",
            "\u001b[32mVal: Epoch = 33 | Loss 1.942 | Accuracy = 44.828\n",
            "\u001b[30mTrain: Epoch = 34 | Loss = 1.768 | Accuracy = 50.313\n",
            "\u001b[32mVal: Epoch = 34 | Loss 1.929 | Accuracy = 44.828\n",
            "\u001b[30mTrain: Epoch = 35 | Loss = 1.539 | Accuracy = 56.875\n",
            "\u001b[32mVal: Epoch = 35 | Loss 1.920 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 36 | Loss = 1.643 | Accuracy = 51.562\n",
            "\u001b[32mVal: Epoch = 36 | Loss 1.911 | Accuracy = 47.414\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 37 | Loss = 1.680 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 37 | Loss 1.921 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 38 | Loss = 1.649 | Accuracy = 52.500\n",
            "\u001b[32mVal: Epoch = 38 | Loss 1.942 | Accuracy = 43.966\n",
            "\u001b[30mTrain: Epoch = 39 | Loss = 1.660 | Accuracy = 51.562\n",
            "\u001b[32mVal: Epoch = 39 | Loss 1.947 | Accuracy = 43.103\n",
            "\u001b[30mTrain: Epoch = 40 | Loss = 1.656 | Accuracy = 47.500\n",
            "\u001b[32mVal: Epoch = 40 | Loss 1.927 | Accuracy = 43.966\n",
            "\u001b[30mTrain: Epoch = 41 | Loss = 1.710 | Accuracy = 49.062\n",
            "\u001b[32mVal: Epoch = 41 | Loss 1.910 | Accuracy = 43.966\n",
            "\u001b[30mTrain: Epoch = 42 | Loss = 1.572 | Accuracy = 51.562\n",
            "\u001b[32mVal: Epoch = 42 | Loss 1.897 | Accuracy = 43.103\n",
            "\u001b[30mTrain: Epoch = 43 | Loss = 1.659 | Accuracy = 52.188\n",
            "\u001b[32mVal: Epoch = 43 | Loss 1.872 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 44 | Loss = 1.560 | Accuracy = 56.875\n",
            "\u001b[32mVal: Epoch = 44 | Loss 1.848 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 45 | Loss = 1.571 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 45 | Loss 1.836 | Accuracy = 48.276\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 46 | Loss = 1.745 | Accuracy = 45.625\n",
            "\u001b[32mVal: Epoch = 46 | Loss 1.845 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 47 | Loss = 1.629 | Accuracy = 52.500\n",
            "\u001b[32mVal: Epoch = 47 | Loss 1.864 | Accuracy = 49.138\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 48 | Loss = 1.526 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 48 | Loss 1.875 | Accuracy = 50.000\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 49 | Loss = 1.668 | Accuracy = 50.938\n",
            "\u001b[32mVal: Epoch = 49 | Loss 1.863 | Accuracy = 50.000\n",
            "\u001b[30mTrain: Epoch = 50 | Loss = 1.580 | Accuracy = 50.625\n",
            "\u001b[32mVal: Epoch = 50 | Loss 1.851 | Accuracy = 50.000\n",
            "\u001b[30mTrain: Epoch = 51 | Loss = 1.593 | Accuracy = 52.812\n",
            "\u001b[32mVal: Epoch = 51 | Loss 1.846 | Accuracy = 51.724\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 52 | Loss = 1.688 | Accuracy = 52.188\n",
            "\u001b[32mVal: Epoch = 52 | Loss 1.883 | Accuracy = 50.000\n",
            "\u001b[30mTrain: Epoch = 53 | Loss = 1.565 | Accuracy = 55.000\n",
            "\u001b[32mVal: Epoch = 53 | Loss 1.904 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 54 | Loss = 1.513 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 54 | Loss 1.881 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 55 | Loss = 1.482 | Accuracy = 53.125\n",
            "\u001b[32mVal: Epoch = 55 | Loss 1.861 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 56 | Loss = 1.512 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 56 | Loss 1.863 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 57 | Loss = 1.480 | Accuracy = 57.500\n",
            "\u001b[32mVal: Epoch = 57 | Loss 1.868 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 58 | Loss = 1.523 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 58 | Loss 1.871 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 59 | Loss = 1.554 | Accuracy = 53.125\n",
            "\u001b[32mVal: Epoch = 59 | Loss 1.865 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 60 | Loss = 1.631 | Accuracy = 53.750\n",
            "\u001b[32mVal: Epoch = 60 | Loss 1.860 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 61 | Loss = 1.660 | Accuracy = 50.313\n",
            "\u001b[32mVal: Epoch = 61 | Loss 1.847 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 62 | Loss = 1.526 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 62 | Loss 1.840 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 63 | Loss = 1.489 | Accuracy = 53.750\n",
            "\u001b[32mVal: Epoch = 63 | Loss 1.844 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 64 | Loss = 1.536 | Accuracy = 53.438\n",
            "\u001b[32mVal: Epoch = 64 | Loss 1.841 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 65 | Loss = 1.669 | Accuracy = 50.938\n",
            "\u001b[32mVal: Epoch = 65 | Loss 1.832 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 66 | Loss = 1.520 | Accuracy = 56.563\n",
            "\u001b[32mVal: Epoch = 66 | Loss 1.821 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 67 | Loss = 1.554 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 67 | Loss 1.834 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 68 | Loss = 1.454 | Accuracy = 60.938\n",
            "\u001b[32mVal: Epoch = 68 | Loss 1.845 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 69 | Loss = 1.448 | Accuracy = 56.250\n",
            "\u001b[32mVal: Epoch = 69 | Loss 1.848 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 70 | Loss = 1.518 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 70 | Loss 1.859 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 71 | Loss = 1.513 | Accuracy = 56.563\n",
            "\u001b[32mVal: Epoch = 71 | Loss 1.858 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 72 | Loss = 1.491 | Accuracy = 54.375\n",
            "\u001b[32mVal: Epoch = 72 | Loss 1.841 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 73 | Loss = 1.491 | Accuracy = 59.688\n",
            "\u001b[32mVal: Epoch = 73 | Loss 1.823 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 74 | Loss = 1.512 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 74 | Loss 1.812 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 75 | Loss = 1.444 | Accuracy = 59.688\n",
            "\u001b[32mVal: Epoch = 75 | Loss 1.800 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 76 | Loss = 1.486 | Accuracy = 58.438\n",
            "\u001b[32mVal: Epoch = 76 | Loss 1.800 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 77 | Loss = 1.489 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 77 | Loss 1.801 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 78 | Loss = 1.554 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 78 | Loss 1.802 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 79 | Loss = 1.529 | Accuracy = 55.625\n",
            "\u001b[32mVal: Epoch = 79 | Loss 1.805 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 80 | Loss = 1.407 | Accuracy = 59.688\n",
            "\u001b[32mVal: Epoch = 80 | Loss 1.807 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 81 | Loss = 1.426 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 81 | Loss 1.809 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 82 | Loss = 1.513 | Accuracy = 56.250\n",
            "\u001b[32mVal: Epoch = 82 | Loss 1.810 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 83 | Loss = 1.375 | Accuracy = 60.938\n",
            "\u001b[32mVal: Epoch = 83 | Loss 1.811 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 84 | Loss = 1.531 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 84 | Loss 1.808 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 85 | Loss = 1.501 | Accuracy = 54.062\n",
            "\u001b[32mVal: Epoch = 85 | Loss 1.806 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 86 | Loss = 1.451 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 86 | Loss 1.805 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 87 | Loss = 1.444 | Accuracy = 57.500\n",
            "\u001b[32mVal: Epoch = 87 | Loss 1.806 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 88 | Loss = 1.445 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 88 | Loss 1.807 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 89 | Loss = 1.506 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 89 | Loss 1.811 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 90 | Loss = 1.474 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 90 | Loss 1.815 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 91 | Loss = 1.428 | Accuracy = 60.625\n",
            "\u001b[32mVal: Epoch = 91 | Loss 1.819 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 92 | Loss = 1.423 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 92 | Loss 1.821 | Accuracy = 49.138\n",
            "\u001b[30mTrain: Epoch = 93 | Loss = 1.390 | Accuracy = 58.438\n",
            "\u001b[32mVal: Epoch = 93 | Loss 1.822 | Accuracy = 48.276\n",
            "\u001b[30mTrain: Epoch = 94 | Loss = 1.401 | Accuracy = 63.438\n",
            "\u001b[32mVal: Epoch = 94 | Loss 1.822 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 95 | Loss = 1.514 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 95 | Loss 1.820 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 96 | Loss = 1.451 | Accuracy = 57.812\n",
            "\u001b[32mVal: Epoch = 96 | Loss 1.818 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 97 | Loss = 1.568 | Accuracy = 53.125\n",
            "\u001b[32mVal: Epoch = 97 | Loss 1.816 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 98 | Loss = 1.452 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 98 | Loss 1.815 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 99 | Loss = 1.450 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 99 | Loss 1.813 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 100 | Loss = 1.440 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 100 | Loss 1.812 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 101 | Loss = 1.446 | Accuracy = 59.375\n",
            "\u001b[32mVal: Epoch = 101 | Loss 1.812 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 102 | Loss = 1.518 | Accuracy = 53.750\n",
            "\u001b[32mVal: Epoch = 102 | Loss 1.813 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 103 | Loss = 1.413 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 103 | Loss 1.816 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 104 | Loss = 1.516 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 104 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 105 | Loss = 1.430 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 105 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 106 | Loss = 1.470 | Accuracy = 57.812\n",
            "\u001b[32mVal: Epoch = 106 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 107 | Loss = 1.373 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 107 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 108 | Loss = 1.444 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 108 | Loss 1.816 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 109 | Loss = 1.489 | Accuracy = 56.250\n",
            "\u001b[32mVal: Epoch = 109 | Loss 1.816 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 110 | Loss = 1.533 | Accuracy = 55.000\n",
            "\u001b[32mVal: Epoch = 110 | Loss 1.817 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 111 | Loss = 1.418 | Accuracy = 57.500\n",
            "\u001b[32mVal: Epoch = 111 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 112 | Loss = 1.515 | Accuracy = 56.250\n",
            "\u001b[32mVal: Epoch = 112 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 113 | Loss = 1.351 | Accuracy = 59.062\n",
            "\u001b[32mVal: Epoch = 113 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 114 | Loss = 1.553 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 114 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 115 | Loss = 1.492 | Accuracy = 56.563\n",
            "\u001b[32mVal: Epoch = 115 | Loss 1.817 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 116 | Loss = 1.338 | Accuracy = 62.813\n",
            "\u001b[32mVal: Epoch = 116 | Loss 1.817 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 117 | Loss = 1.459 | Accuracy = 56.563\n",
            "\u001b[32mVal: Epoch = 117 | Loss 1.816 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 118 | Loss = 1.413 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 118 | Loss 1.818 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 119 | Loss = 1.406 | Accuracy = 56.875\n",
            "\u001b[32mVal: Epoch = 119 | Loss 1.821 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 120 | Loss = 1.400 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 120 | Loss 1.823 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 121 | Loss = 1.406 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 121 | Loss 1.821 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 122 | Loss = 1.370 | Accuracy = 61.875\n",
            "\u001b[32mVal: Epoch = 122 | Loss 1.820 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 123 | Loss = 1.447 | Accuracy = 59.688\n",
            "\u001b[32mVal: Epoch = 123 | Loss 1.819 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 124 | Loss = 1.426 | Accuracy = 59.688\n",
            "\u001b[32mVal: Epoch = 124 | Loss 1.818 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 125 | Loss = 1.431 | Accuracy = 59.062\n",
            "\u001b[32mVal: Epoch = 125 | Loss 1.817 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 126 | Loss = 1.445 | Accuracy = 57.812\n",
            "\u001b[32mVal: Epoch = 126 | Loss 1.816 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 127 | Loss = 1.370 | Accuracy = 61.562\n",
            "\u001b[32mVal: Epoch = 127 | Loss 1.815 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 128 | Loss = 1.614 | Accuracy = 53.125\n",
            "\u001b[32mVal: Epoch = 128 | Loss 1.815 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 129 | Loss = 1.416 | Accuracy = 55.625\n",
            "\u001b[32mVal: Epoch = 129 | Loss 1.815 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 130 | Loss = 1.428 | Accuracy = 59.375\n",
            "\u001b[32mVal: Epoch = 130 | Loss 1.815 | Accuracy = 47.414\n",
            "\u001b[30mTrain: Epoch = 131 | Loss = 1.506 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 131 | Loss 1.814 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 132 | Loss = 1.407 | Accuracy = 56.875\n",
            "\u001b[32mVal: Epoch = 132 | Loss 1.814 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 133 | Loss = 1.482 | Accuracy = 53.750\n",
            "\u001b[32mVal: Epoch = 133 | Loss 1.815 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 134 | Loss = 1.385 | Accuracy = 63.750\n",
            "\u001b[32mVal: Epoch = 134 | Loss 1.815 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 135 | Loss = 1.473 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 135 | Loss 1.814 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 136 | Loss = 1.429 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 136 | Loss 1.814 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 137 | Loss = 1.429 | Accuracy = 57.500\n",
            "\u001b[32mVal: Epoch = 137 | Loss 1.814 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 138 | Loss = 1.423 | Accuracy = 60.625\n",
            "\u001b[32mVal: Epoch = 138 | Loss 1.815 | Accuracy = 46.552\n",
            "\u001b[30mTrain: Epoch = 139 | Loss = 1.364 | Accuracy = 61.562\n",
            "\u001b[32mVal: Epoch = 139 | Loss 1.815 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 140 | Loss = 1.309 | Accuracy = 64.375\n",
            "\u001b[32mVal: Epoch = 140 | Loss 1.814 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 141 | Loss = 1.541 | Accuracy = 52.500\n",
            "\u001b[32mVal: Epoch = 141 | Loss 1.814 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 142 | Loss = 1.383 | Accuracy = 59.375\n",
            "\u001b[32mVal: Epoch = 142 | Loss 1.814 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 143 | Loss = 1.484 | Accuracy = 55.625\n",
            "\u001b[32mVal: Epoch = 143 | Loss 1.814 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 144 | Loss = 1.380 | Accuracy = 56.563\n",
            "\u001b[32mVal: Epoch = 144 | Loss 1.817 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 145 | Loss = 1.463 | Accuracy = 59.375\n",
            "\u001b[32mVal: Epoch = 145 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 146 | Loss = 1.440 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 146 | Loss 1.820 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 147 | Loss = 1.436 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 147 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 148 | Loss = 1.408 | Accuracy = 57.500\n",
            "\u001b[32mVal: Epoch = 148 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 149 | Loss = 1.399 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 149 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 150 | Loss = 1.416 | Accuracy = 58.750\n",
            "\u001b[32mVal: Epoch = 150 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 151 | Loss = 1.389 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 151 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 152 | Loss = 1.453 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 152 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 153 | Loss = 1.424 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 153 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 154 | Loss = 1.460 | Accuracy = 54.062\n",
            "\u001b[32mVal: Epoch = 154 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 155 | Loss = 1.390 | Accuracy = 59.062\n",
            "\u001b[32mVal: Epoch = 155 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 156 | Loss = 1.524 | Accuracy = 54.375\n",
            "\u001b[32mVal: Epoch = 156 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 157 | Loss = 1.403 | Accuracy = 61.875\n",
            "\u001b[32mVal: Epoch = 157 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 158 | Loss = 1.367 | Accuracy = 64.062\n",
            "\u001b[32mVal: Epoch = 158 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 159 | Loss = 1.604 | Accuracy = 52.188\n",
            "\u001b[32mVal: Epoch = 159 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 160 | Loss = 1.321 | Accuracy = 62.500\n",
            "\u001b[32mVal: Epoch = 160 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 161 | Loss = 1.397 | Accuracy = 59.688\n",
            "\u001b[32mVal: Epoch = 161 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 162 | Loss = 1.465 | Accuracy = 56.250\n",
            "\u001b[32mVal: Epoch = 162 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 163 | Loss = 1.440 | Accuracy = 55.625\n",
            "\u001b[32mVal: Epoch = 163 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 164 | Loss = 1.361 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 164 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 165 | Loss = 1.415 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 165 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 166 | Loss = 1.306 | Accuracy = 66.250\n",
            "\u001b[32mVal: Epoch = 166 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 167 | Loss = 1.476 | Accuracy = 55.937\n",
            "\u001b[32mVal: Epoch = 167 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 168 | Loss = 1.349 | Accuracy = 62.813\n",
            "\u001b[32mVal: Epoch = 168 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 169 | Loss = 1.386 | Accuracy = 60.938\n",
            "\u001b[32mVal: Epoch = 169 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 170 | Loss = 1.384 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 170 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 171 | Loss = 1.353 | Accuracy = 60.938\n",
            "\u001b[32mVal: Epoch = 171 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 172 | Loss = 1.455 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 172 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 173 | Loss = 1.425 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 173 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 174 | Loss = 1.420 | Accuracy = 59.375\n",
            "\u001b[32mVal: Epoch = 174 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 175 | Loss = 1.325 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 175 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 176 | Loss = 1.323 | Accuracy = 61.562\n",
            "\u001b[32mVal: Epoch = 176 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 177 | Loss = 1.490 | Accuracy = 56.875\n",
            "\u001b[32mVal: Epoch = 177 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 178 | Loss = 1.294 | Accuracy = 63.125\n",
            "\u001b[32mVal: Epoch = 178 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 179 | Loss = 1.345 | Accuracy = 63.125\n",
            "\u001b[32mVal: Epoch = 179 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 180 | Loss = 1.478 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 180 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 181 | Loss = 1.465 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 181 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 182 | Loss = 1.400 | Accuracy = 59.375\n",
            "\u001b[32mVal: Epoch = 182 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 183 | Loss = 1.404 | Accuracy = 59.062\n",
            "\u001b[32mVal: Epoch = 183 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 184 | Loss = 1.421 | Accuracy = 53.438\n",
            "\u001b[32mVal: Epoch = 184 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 185 | Loss = 1.422 | Accuracy = 56.250\n",
            "\u001b[32mVal: Epoch = 185 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 186 | Loss = 1.531 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 186 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 187 | Loss = 1.405 | Accuracy = 57.812\n",
            "\u001b[32mVal: Epoch = 187 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 188 | Loss = 1.489 | Accuracy = 55.312\n",
            "\u001b[32mVal: Epoch = 188 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 189 | Loss = 1.430 | Accuracy = 56.875\n",
            "\u001b[32mVal: Epoch = 189 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 190 | Loss = 1.406 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 190 | Loss 1.819 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 191 | Loss = 1.471 | Accuracy = 57.188\n",
            "\u001b[32mVal: Epoch = 191 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 192 | Loss = 1.415 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 192 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 193 | Loss = 1.421 | Accuracy = 60.000\n",
            "\u001b[32mVal: Epoch = 193 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 194 | Loss = 1.427 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 194 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 195 | Loss = 1.391 | Accuracy = 59.062\n",
            "\u001b[32mVal: Epoch = 195 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 196 | Loss = 1.426 | Accuracy = 57.812\n",
            "\u001b[32mVal: Epoch = 196 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 197 | Loss = 1.376 | Accuracy = 58.125\n",
            "\u001b[32mVal: Epoch = 197 | Loss 1.818 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 198 | Loss = 1.477 | Accuracy = 54.688\n",
            "\u001b[32mVal: Epoch = 198 | Loss 1.817 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 199 | Loss = 1.459 | Accuracy = 55.000\n",
            "\u001b[32mVal: Epoch = 199 | Loss 1.817 | Accuracy = 45.690\n",
            "\u001b[30mTrain: Epoch = 200 | Loss = 1.379 | Accuracy = 60.312\n",
            "\u001b[32mVal: Epoch = 200 | Loss 1.817 | Accuracy = 45.690\n",
            "\u001b[36mBest Acc -->  51.724137931034484\n",
            "\u001b[36mLast Acc -->  45.689655172413794\n"
          ]
        }
      ]
    }
  ]
}